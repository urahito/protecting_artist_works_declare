# クリエイター作品保護の宣言(Protecting artist works Declare)

## 再確認：本宣言のライセンスについて

CC-NC-ND v4.0（クリエイティブ・コモンズ・ライセンス：氏名表示-非営利-改変不可）に基づき公開します

<p xmlns:cc="http://creativecommons.org/ns#" >This repository is licensed under <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" alt=""><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" alt=""><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/nc.svg?ref=chooser-v1" alt=""><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/nd.svg?ref=chooser-v1" alt=""></a></p>

著者/author: Urahito （うらひと）  

## はじめに：宣言の背景

### 私の理解として (ver:2024.12-0)

- 2022年以前から、盗作・なりすましの被害は一定数存在し、被害に遭ったクリエイターにとって、特に日本ではインターネット上での加害行為への訴訟が煩雑で非常に時間がかかるという問題(注1)がありました。
  - 注1: 2022年秋に情報開示請求に関わる法律改正が施行されています。 => [【2022年10月1日施行】 プロバイダ責任制限法改正とは？ 改正ポイントを分かりやすく解説！](https://keiyaku-watch.jp/media/hourei/provider-seigen-sekinin/)
- また、2021年には特に問題視している「画像生成ＡＩ」がサービス開始しています。
- 2022年夏に「Stable Diffusion（注2）」がオープンソース化したことにより、問題が急速に広まったと認識しています。
  - 注２：「取り扱う用語」参照
- **これは生成ＡＩユーザーも、生成ＡＩに対する批判者にも言えることですが**、それ以降、以下のような被害を見聞きしており、立場に関係無く、してはならない事であることを明記します。（本リポジトリ・宣言においても同様とします）
  - 生成ＡＩについて発言した人に対する暴言、過度な要求、つきまとい、その他嫌がらせ、業務の妨害
  - 生成ＡＩへの発言や受けた非難を理由にした犯罪・危害の予告
    - 規制を求める人の中にも、暴言などの行為があることも認識しています
- 以上のようなそれぞれの問題が、一連の問題・議論として非難されており、（悪印象を与える一部の生成ＡＩユーザーが単に「ＡＩ」と書くことによって）ＡＩ全般への偏見・風評被害に繋がっていると考えています。
  - もっとも、自動運転技術など別分野で用いられる「ＡＩ」が関連する事件・事故もあるため、それが原因のすべてではありません。

#### 参考資料

※私が確認し、本宣言として適当であると判断した場合、関係資料として追記します。  

- [まさに「世界変革」──この2カ月で画像生成AIに何が起きたのか？：新連載　清水亮の「世界を変えるAI」（1/5 ページ） - ITmedia NEWS](https://www.itmedia.co.jp/news/articles/2210/25/news158.html)
- <a href="https://www.bunka.go.jp/seisaku/chosakuken/aiandcopyright.html" target="_blank">AIと著作権について | 文化庁</a>
- [AI画像生成・生成系AI 問題まとめwiki - atwiki（アットウィキ）](https://w.atwiki.jp/genai_problem/pages/1.html)
- [AIの成長を裏で支える人間の存在　「ゴーストワーカー」とは｜『日本の人事部 HRテクノロジー』](https://jinjibu.jp/hrt/keyword/detl/1111/)

### 取り扱う用語 (ver:2025.06-0)

- 「生成ＡＩ」「コンテンツ系生成ＡＩ」
  - （コンテンツ系）生成AIは訓練データと同一分野の出力物を生成するもの全般を指すこととします。
  - ツールとして「Stable Diffusion(以下ＳＤ)」「nijijourney」（他にも認識しているものはありますが）、データとして「NovelAI」を代表例とします。
  - また、権利侵害が疑われるものには、文章・文芸・音声・動画など芸術作品・評論などのコンテンツが含まれており、上記はあくまで**代表するもの**として扱い、原則としてこれらの問題に関係するもの全般に読み替えるものとします。
    - そのほか、生成ＡＩに関係する（or連携により利用可能な）サービスは[別ページ](/ja-JP/gen_ai_service_list.md)にまとめています。
  - コンテンツ系以外に、専門家がその責任のもとで扱う生成ＡＩもありますが、**規制を求める文脈上では「生成ＡＩ」は「非オプトイン型（オプトインでないもの）のコンテンツ系生成ＡＩ」を指すもの**として取り扱います。
- 「ＡＩ全般」
  - 「生成ＡＩ」を含めた、いわゆる「人工知能」と呼ばれるもの全般
    - 内包するものとして「機械学習」「ディープラーニング（深層学習）」があり、ここでいう「学習」は「人間がデータを与えて訓練し、ＡＩが学習する」ものとして扱い、その元データ（教師データ）を指し示すときは「訓練データ」と表記します。
  - また、単にアルゴリズムであるものが一般に「ＡＩ」と呼ばれる場合、文脈に応じて「ＡＩとされるアルゴリズム」と表記する場合があります。
    - これを本宣言上では「ＡＩ」として扱いません。
- 「生成ＡＩモデル」
  - 主に、無断転載サイト『Danbooru』から『NovelAI』を経由して取り込まれ、復元可能な形でデータベース化されたもの。
    - [【炎上】画像AI『NovelAI Diffusion』が無断転載サイト『Danbooru』を学習させていた・・・](https://matomedane.jp/page/114714)
    - また、実写系としてグラビアアイドルの画像の改変（NSFW化）や児童ポルノ画像を復元可能、それを元に実在の人物の画像を加工可能であり、これらは「ディープフェイク」問題として社会問題となっています。
  - ただし、以下のようにもＡＩモデルが分類されることに留意する
    - オプトイン型：2024年12月にはオプトイン型の画像生成ＡＩモデルが第三者機関からの認証を受けている
    - 専門業務補助型：医療向けなど、専門家の業務の補助目的で、最終的な責任を専門家が持つもの（通常オプトイン型である認識）
- 「オプトイン」「オプトアウト」
  - オプトイン：本人の同意・同意拒否の表明をもって、同意の場合に当該情報の利用を行う方式
    - 意思表明されてはじめて有効
    - （例）YouTuber, VTuber等のファンアートタグへ投稿することをもって「応募」とする
  - オプトアウト：本人の拒否・脱退の意思表明をもって、当該情報の利用を停止する方式
    - 意思表明されたら無効
    - （例）電話等の着信拒否
- 「NSFW」「センシティブ」
  - NSFWは「Not show for work」の略で「仕事中の閲覧に適さないもの」といった意味。
  - センシティブ：直訳で「繊細（なもの）」であるが、ここでは「取扱いに注意を要するもの」として記載する（これにはNSFWを含む。文脈によってはNSFWと同じ意味として扱う）。

## 1.基本的な立場の表明

- 生成ＡＩの、オプトイン型のモデルを認めますが、乱用防止の規制が必要であると考えます。
- 生成ＡＩの、非オプトイン型のモデルについて、最低限ラインとして「求める規制」の項に挙げるような規制を求めています。

### 1.1. 論点 (ver:2026.06-0)

1. 訓練元データの違法性：無断転載サイト（主に『Danbooru』）やpinterestなどコレクションサイトなどへの直接アップロードは、現行法（著作権法）に抵触するのではないか
1. ＡＩモデル（ＡＩ訓練データ）：生成ＡＩモデル開発企業は、フィルタリング・マスキングなど必要な措置を取らずに、モデルを提供している（除外する例もあるらしいが、その透明性はほとんどの場合で確保されていない）
   1. 関連「ゴーストワーカー」：ＡＩが自発的に新しい訓練データをタグ付けするとは限らず、ＡＩタグ付け労働がデータ入力業務の求人情報として存在する。
   2. 画像生成ＡＩにおいて、児童虐待画像へのタグ付けなど、労働者の精神的な苦痛を伴う作業も発生しているという海外からの報告がある。（これが認識されていないのであれば、求人の存在する日本でも同様の事例はあると考えられる）
   3. 資料: [AIの成長を裏で支える人間の存在　「ゴーストワーカー」とは｜『日本の人事部 HRテクノロジー』](https://jinjibu.jp/hrt/keyword/detl/1111/)
2. ＡＩ生成コンテンツを出力するソフトウェア（ＡＩ生成ソフト）：先述のＳＤなどを代表例に、ＡＩモデルからオリジナルデータと誤認しうる画像を出力できる（企業ＩＰ作品など）
3. ＡＩ生成ソフトのユーザー：大別して以下の問題があります
   1. オリジナル作品（商業作品含む）と類似しているデータと知りながら、ＳＮＳ等に作品としてアップロードする
      1. 具体的にはChatGPTで生成される「ジブリ風」など
   2. 自ら制作したデータでないにも関わらず、コンテスト・コンペ等に提出する
   3. Lora（強化学習データ）で絵柄を寄せ、オリジナルアーティストと誤認させる（場合によっては、オリジナルアーティストを騙り販売・納品を行う可能性がある）
4. その他、立場に関係無い問題　※そもそも触法する可能性があり、本宣言では直接的に論じませんが、これらは生成ＡＩへの賛否に関係無く、通常のトラブルと同じく非常に不適切であると考えます
   1. 暴言、過度な要求、つきまとい、その他嫌がらせ、業務の妨害（生成ＡＩについて発言した人に対するものも考慮する）
   2. 犯罪・危害の予告（生成ＡＩへの発言や受けた非難を理由にしたものも考慮する）

### 1.1.1. 取り扱う範囲

- 訓練元データ
- ＡＩモデル（ＡＩ訓練データ）
- ＡＩ生成コンテンツを出力するソフトウェア（ＡＩ生成ソフト）
- ＡＩ生成ソフトのユーザー

『これらのうち１つでも欠けていれば最終的な権利侵害が成立しないため、一連の流れとして横断して規制が必要である』と考えます。  

#### 著作権法第30条の4に関して

最終的に「単なるデータではなく、作品と認識させる（鑑賞させる）」ことが成立しているケースが多く、（著作権者の）権利制限は有効とならず、権利侵害を訴えることは可能と認識しています。  
⇒参照： [AIと著作権について | 文化庁](https://www.bunka.go.jp/seisaku/chosakuken/aiandcopyright.html) > 『著作権法第30条の4等の基本的な考え方について』PDF、[「デジタル化・ネットワーク化の進展に対応した 柔軟な権利制限規定に関する基本的な考え方 （著作権法第30条の４，第47条の４及び第47条の５関係） 」](https://www.bunka.go.jp/seisaku/chosakuken/hokaisei/h30_hokaisei/pdf/r1406693_17.pdf)（問７、問９など）

### 1.2. 求める規制 (ver:2025.06-0)

※先述の「その他、立場に関係無い問題」は本筋から外れるため言及しません。

- 開発企業について
  - コンテンツの形態・由来に関わらず、オプトイン以外でのＡＩ訓練の禁止、または厳格な条件でのみ許可（制限）
    - 訓練データは「作品」であり、権利者の知らない間に「利用していないサービス・ソフト」に使われることを防ぐため、オプトイン型が適切と考えます
  - 第三者機関による生成ＡＩツールの認証・年次審査の義務化、および違反時の罰則（プライバシーマークと同様）
    - ＡＩタグ付け労働（ゴーストワーカー）についての厳格な監査が行われること（単に労働の観点だけではなく、画像等による性被害・加害の防止の観点で必要）
  - 認証外の生成ＡＩツールのリリースの制限
  - 生成ＡＩツールの訓練データの透明化（追跡の容易性）・類似判定の実装の義務化
  - 権利侵害ユーザーのアカウント・利用ライセンスの停止の義務化、あるいは情報開示責務の規定
  - 違反時の行政処分、悪質な場合は刑事告訴の規定
- ユーザーについて
  - 権利侵害データが復元可能な生成ＡＩモデルの所持の禁止
  - 認証外の生成ＡＩツールの利用の制限

## 2.生成ＡＩからの保護に関する、クライアントとしての宣言

### 2.1. 依頼時のマニュアル (ver:2024.12-0)

- 原則としてクリエイターの提示する内容を優先しますが、必要と判断した場合、納品物の保護措置を行います。
- ＳＮＳによっては制作者名の表示が必須になるため、文面または画像内にテキストや専用ロゴにより表記するようにします。
  - この手段について、クリエイターから指定があれば、基本的にそれに従います。
  - 複数の関係者が関わる場合、クライアントにとっても負担の少ない形をご相談させていただくことがあります。
    - 例：クリエイター名＋依頼ページへのリンクなど
- 免責事項として、ＳＮＳの移動やクリエイター名の変更をクライアントが把握出来ず、対応が遅れることがあります。（移動を悟られたくない場合、ＤＭ等非公開の手段でお知らせ頂けると幸いです）

### 2.2. 健全なＳＮＳ利用のためのガイドライン (ver:2024.12-0)

- 原則として、ＳＮＳ利用に際し、心理的安全性の確保に重点を置きます。
- 生成ＡＩの問題については、個々の内容や自身の見解との近さに応じて判断することとし、不安を感じる場合や、より正確な情報や作品を求めるために対応を行います。
- トラブル予防の観点で、ＳＮＳ等に備わっている閲覧制限機能（非公開化、ブロック、ミュート等）を積極的に活用します。
- 特に、先述の「その他、立場に関係無い問題」と判断出来る発言があった場合は、その賛否に関係無く閲覧制限機能を利用します。
- ＳＮＳの移動に際し、別のＳＮＳで先述のような行為を確認できるユーザーと同一であることを確認出来た場合、移動先ＳＮＳでもトラブル予防のためこの措置を行うことがあります。


### 2.3. 作品公開の指針 (ver:2025.06-0)

- 意図せず軽微なＡＩ（コンテンツ系生成ＡＩ、または創作への利用用途を除く）利用を行う可能性があります。
  - ディープラーニングを含むものは、出力先のコンテンツが自身で正確性を判断出来る用途に限定します。（例：英文制作時の英語からの和訳＋辞書利用）
  - 認識している範囲で利用の回避に努めます。利用の意図に関わらず起動する生成AI（検索要約等）については、再検索等で表示回避を行い、正確な情報の収集に努めます
- 他者の制作物（依頼等による制作物）を含まないで構成される作品（自身の制作、軽微なアルゴリズム・ＡＩ利用を含む）については、積極的にＡＩ訓練予防措置を行います。
  - 主に、ウォーターマークやノイズパターンの付与、画像内に規約の記載などを行います。
- 他者の制作物を含む場合は、画像内へのクレジットの記載（必要があれば投稿文への記載）に加え、アップロード先の環境で悪用される恐れがあると判断した場合、上記の措置を追加します。
  - Ｗｅｂ上で安全な場所はないと考えているため、事実上多くの場合において追加措置を行う考えです。
